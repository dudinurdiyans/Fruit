# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ul1jBdzF3hL6wO1zbptwLDTLxdkco4-Z
"""

import os
import streamlit as st
import tensorflow as tf
import numpy as np
from io import BytesIO
import requests
import zipfile

# Constants
DATASET_URL = "https://www.kaggleusercontent.com/api/v1/datasets/dudinurdiyansah/fruit-ripeness-classifier.zip"
MODEL_URL = "https://drive.google.com/file/d/1U46XN0qPFqNy3P49QLpy4T-F6lJoVViQ/view?usp=sharing"  # Ganti dengan link model Anda
DATASET_DIR = "fruit-ripeness-classifier/DatasetV2"
MODEL_FILE = "best_model.keras"

# Functions to download dataset and model
def download_and_extract_dataset():
    if not os.path.exists(DATASET_DIR):
        st.info("Downloading dataset from Kaggle...")
        response = requests.get(DATASET_URL, stream=True)
        with open("dataset.zip", "wb") as f:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    f.write(chunk)

        st.info("Extracting dataset...")
        with zipfile.ZipFile("dataset.zip", "r") as zip_ref:
            zip_ref.extractall()
        os.remove("dataset.zip")
        st.success("Dataset downloaded and extracted.")

def download_model():
    if not os.path.exists(MODEL_FILE):
        st.info("Downloading model...")
        response = requests.get(MODEL_URL, stream=True)
        with open(MODEL_FILE, "wb") as f:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    f.write(chunk)
        st.success("Model downloaded.")

# Initialize Streamlit app
st.title("Fruit Ripeness Classifier")
st.write("Upload an image to classify its ripeness!")

# Ensure dataset and model are available
download_and_extract_dataset()
download_model()

# Load model
st.info("Loading model...")
model = tf.keras.models.load_model(MODEL_FILE)
st.success("Model loaded successfully.")

# Define class names (update based on your dataset structure)
classes = [
    # Ripe categories
    "RipeApple", "RipeBanana", "RipeDragonFruit",  "RipeGrape",
    "RipeGuava", "RipeOrange", "RipePapaya", "RipePineapple",
    "RipePomegranate", "RipeStrawberry",
    # Unripe categories
    "UnripeApple", "UnripeBanana", "UnripeDragonFruit", "UnripeGrape",
    "UnripeGuava", "UnripeOrange", "UnripePapaya", "UnripePineapple",
    "UnripePomegranate", "UnripeStrawberry",
    # Rotten Categories
    "RottenApple", "RottenBanana", "RottenDragonFruit", "RottenGrape",
    "RottenGuava", "RottenOrange", "RottenPapaya", "RottenPineapple",
    "RottenPomegranate", "RottenStrawberry"
]

# Upload file
uploaded_file = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Display uploaded image
    st.image(uploaded_file, caption="Uploaded Image", use_column_width=True)

    # Preprocess image
    image = tf.keras.utils.load_img(uploaded_file, target_size=(224, 224))
    image_array = tf.keras.utils.img_to_array(image)
    image_array = np.expand_dims(image_array, axis=0)

    # Predict
    st.info("Classifying image...")
    predictions = model.predict(image_array, verbose=0)[0]
    confidence_score = np.max(predictions)
    predicted_index = np.argmax(predictions)
    predicted_class = classes[predicted_index]

    # Display result
    if confidence_score > 0.7:
        st.success(f"Predicted Class: {predicted_class}")
        st.write(f"Confidence: {confidence_score:.2f}")
    else:
        st.warning("The model is not confident about the prediction. Please upload another image.")